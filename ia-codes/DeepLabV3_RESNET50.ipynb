{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvvEPZP_zwa6"
      },
      "source": [
        "**Possibilitando acesso a drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qHM8VHCjUGLR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69dfb22-b2ea-47b6-af82-153a351a5ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ],
      "metadata": {
        "id": "-4dBY6sUFX7e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nabwFGiz5w5"
      },
      "source": [
        "**Importando bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_7C4xX0NUzmL"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import time\n",
        "import numpy as np \n",
        "import cv2 \n",
        "import torchvision.models.segmentation \n",
        "import torch \n",
        "import torchvision.transforms as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "#import segmentation_models_pytorch as smp\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import pandas as pd\n",
        "import random\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Segmentation Model\n",
        "#from torchvision.io.image import read_image\n",
        "#from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
        "#from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "# Função de Recall\n",
        "from sklearn.metrics import recall_score\n",
        "# Função de F1\n",
        "from sklearn.metrics import f1_score\n",
        "# Função de Precision\n",
        "from sklearn.metrics import precision_score\n",
        "# Função de Accuracy\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp9Me-seaoqY"
      },
      "source": [
        "**Inicializando constantes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WqFtRtwoIZ8T"
      },
      "outputs": [],
      "source": [
        "model_name = 'DeepLabV3_RESNET50'\n",
        "model_folder = f'/content/drive/MyDrive/DEV/saved-weights/{model_name}/'\n",
        "\n",
        "ImagesFolder=\"/content/drive/MyDrive/DEV/corte2/\" # ALTERAR ESSE CAMINHO PARA A PASTA CORTE 2 NA NUVEM COM GPUb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "batchSize = 2 # Esse valor precisa ser divisor do número de imagens no treino\n",
        "batchSize_val = 2 # Esse valor precisa ser divisor do número de imagens na validação\n",
        "Learning_Rate = 1e-5"
      ],
      "metadata": {
        "id": "iqvCNFiNmKMn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY8LXMuAasic"
      },
      "source": [
        "**Carregando arquivo com dataframe do dataset \"aleatoriezado\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwKoSvj_F4L4",
        "outputId": "aa55fe84-5837-48d6-d860-939e7eca8406"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Train    640\n",
              "Test      78\n",
              "Val       78\n",
              "Name: Status, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Carregando dataframe de um arquivo chamado \"all_dataset_dataframe.csv\"\n",
        "# Referencia https://towardsdatascience.com/how-to-read-csv-file-using-pandas-ab1f5e7e7b58\n",
        "df = pd.read_csv(f'{ImagesFolder}all_dataset_dataframe.csv') # ALTERAR ESSE CAMINHO PARA A LOCALIZAÇÃO DO DATAFRAME NA NUVEM COM GPU\n",
        "df['Status'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywxPjkHJbvi_"
      },
      "source": [
        "**Lendo valores de desvio padrão e média de um arquivo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPZIgdYkmREx",
        "outputId": "1241587c-79e7-4174-9732-1178c49a262d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6604449458815983, 0.6988043731738397, 0.6452534234104293]\n",
            "[0.1753238443181036, 0.19331901534376825, 0.1546044630633522]\n"
          ]
        }
      ],
      "source": [
        "# Lendo a média e desvio padrão do arquivo \"mean_and_std_list.txt\"\n",
        "mean_and_std_list_file = open(f\"{ImagesFolder}mean_and_std.txt\", \"r\")\n",
        "content_list = mean_and_std_list_file.readlines()\n",
        "\n",
        "mean = [float(integer) for integer in content_list[1].split(' ')[0:3]]\n",
        "std = [float(integer) for integer in content_list[3].split(' ')[0:3]]\n",
        "\n",
        "print(mean)\n",
        "print(std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnydFlHET-QS"
      },
      "source": [
        "**Declaração do Dataset pelo Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sjrWa2An7FgK"
      },
      "outputs": [],
      "source": [
        "# Referência: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "class CustomImageDataset(Dataset):\n",
        "    \n",
        "  def __init__(self, df):\n",
        "    self.dataframe = df\n",
        "    #----------------------------------------------Funções de transformação-------------------------------------------------------------------#\n",
        "    self.transformImg=tf.Compose([tf.ToPILImage(), tf.ToTensor(),tf.Normalize((mean[0], mean[1], mean[2]), (std[0], std[1], std[2]))])\n",
        "    self.transformMask=tf.Compose([tf.ToPILImage(), tf.ToTensor()])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    pair_path = os.path.join(ImagesFolder,  self.dataframe.iloc[idx].Path)\n",
        "    Img = cv2.imread(os.path.join(pair_path, \"img.png\"))\n",
        "    Label = cv2.imread(os.path.join(pair_path, \"label.png\"),0)\n",
        "\n",
        "    mask = np.zeros(Img.shape[0:2],np.float32)\n",
        "    mask[Label != 0] = 1 # set to 1 only the pixels that corresponds to the mask\n",
        "\n",
        "    image = self.transformImg(Img)\n",
        "    label = self.transformMask(mask)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lrUgP-UOOQFf"
      },
      "outputs": [],
      "source": [
        "ds_train=CustomImageDataset(df[df['Status'] == 'Train'])\n",
        "ds_val=CustomImageDataset(df[df['Status'] == 'Val'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ds_train))\n",
        "print(len(ds_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fim9P8bay_Ga",
        "outputId": "c99b4adc-9f2e-48aa-fd9b-0d5cce97cab9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "640\n",
            "78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fa0qK2VULgJ"
      },
      "source": [
        "**Instanciação do DataLoader's pelo Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xi_buGBPQ1Jd"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(ds_train, batch_size=batchSize, shuffle=True)\n",
        "val_dataloader = DataLoader(ds_val, batch_size=batchSize_val, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK6z-HMjUclc"
      },
      "source": [
        " **Definição da estrutura DeepLabV3_RESNET50**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsaE6vAic3wN"
      },
      "source": [
        " Referência: https://pytorch.org/vision/stable/models/generated/torchvision.models.segmentation.deeplabv3_resnet50.html#torchvision.models.segmentation.DeepLabV3_ResNet50_Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "0PLB8GVLNg7d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "cd9e3238414444188a1a14b954f73269",
            "2a4fef251cc4499d8ba87649e98b75b2",
            "cc30bb27a2594fc09a40f0260ee9296b",
            "f0bafad0c8f24fff82f68f1b2bab6c8e",
            "e25bd1fb29db46ab8ff6473e1ada8e2c",
            "a9bfe57cb5da466ebe497d1602f7648b",
            "7fb704eaf8b44c2ca7fa204319e6cd52",
            "bee317ec30d84a5e925a570d25d96cd8",
            "cb7dd525c8744e3d929f231e6f77a083",
            "5d625c2dc4624e279cb75396a4e8e5b5",
            "a92c759848ba4296a52f2616fd5bd1da"
          ]
        },
        "id": "_AwKg3JNPVX5",
        "outputId": "e67e7f18-d200-44ed-c1aa-448777cfc09b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/161M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd9e3238414444188a1a14b954f73269"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#--------------Load and set net and optimizer-------------------------------------\n",
        "Net = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True) # Load net\n",
        "Net.classifier[4] = torch.nn.Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1)) # Change final layer to 2 classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "Net=Net.to(device)\n",
        "optimizer=torch.optim.Adam(params=Net.parameters(),lr=Learning_Rate) # Create adam optimizer"
      ],
      "metadata": {
        "id": "dfbE59OiNzRV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftzhro928ZzG"
      },
      "source": [
        "**Treinamento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxHqvnR-P5-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebe7699-1c40-4872-b21c-33d39d310893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training epoch: 0\n"
          ]
        }
      ],
      "source": [
        "epoch = []\n",
        "\n",
        "train_loss = []\n",
        "train_loss_sum = 0\n",
        "\n",
        "val_loss = []\n",
        "val_loss_sum = 0\n",
        "\n",
        "cont2 = 0\n",
        "\n",
        "val_metrics = {'accuracy': [], 'precision_macro' : [], 'precision_micro' : [], 'recall' : [], \n",
        "               'f1_macro' : [], 'f1_micro' : [], 'training_loss' : [], 'validation_loss' : []}\n",
        "loss_dict = {'training' : [], 'validation' : []} \n",
        "\n",
        "train_prev_loss = float('-inf')\n",
        "train_best_loss = float('inf')\n",
        "train_last_improvement = 0\n",
        "\n",
        "\n",
        "val_prev_loss = float('-inf')\n",
        "val_best_loss = float('inf')\n",
        "val_last_improvement = 0\n",
        "\n",
        "patience_n_iterations = 5\n",
        "patience_min_threshold = 0.01\n",
        "\n",
        "\n",
        "#Net.load_state_dict(torch.load(\"0.torch\")) # Load trained model\n",
        "start = time.time()\n",
        "for itr in range(n_epochs): # Training loop\n",
        "  print(f'training epoch: {itr}')\n",
        "  batch_it = 0\n",
        "  train_loss_sum = 0\n",
        "  \n",
        "  #TRAINING\n",
        "  Net.train()\n",
        "  for images, mask in train_dataloader:\n",
        "    Net.zero_grad()\n",
        "    \n",
        "    # Iterar sobre o dataloader do treino    \n",
        "    mask = mask.squeeze()\n",
        "    images = torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n",
        "    mask = torch.autograd.Variable(mask, requires_grad=False).to(device) # Load annotation\n",
        "    \n",
        "    Pred=Net(images)['out'] # make prediction\n",
        "    \n",
        "    criterion = torch.nn.CrossEntropyLoss() # Set loss function\n",
        "    \n",
        "    Loss = criterion(Pred,mask.long()) # Calculate cross entropy loss    \n",
        "    Loss.backward() # Backpropogate loss\n",
        "    optimizer.step() # Apply gradient descent change to weight\n",
        "    \n",
        "    #print(f'Training Batch Iteration = {batch_it}, Training Loss = {Loss.data.cpu().numpy()}')\n",
        "    train_loss_sum += Loss.data.cpu().numpy()\n",
        "    batch_it += 1\n",
        "    \n",
        "  delta = 1 - train_loss_sum / train_prev_loss\n",
        "  if(delta >= patience_min_threshold):\n",
        "    train_prev_loss = train_loss_sum\n",
        "    train_last_improvement = 0  \n",
        "  else:\n",
        "    train_last_improvement += 1\n",
        "    if train_last_improvement >= patience_n_iterations:\n",
        "        break\n",
        "  \n",
        "  train_loss.append(train_loss_sum/len(train_dataloader))\n",
        "\n",
        "  #VALIDATION \n",
        "  val_loss_sum = 0\n",
        "\n",
        "  Net.eval()\n",
        "  with torch.no_grad():\n",
        "        \n",
        "    for images, mask in val_dataloader:\n",
        "        \n",
        "      mask = mask.squeeze()\n",
        "      AnnMap = np.zeros(mask.shape,np.float32)\n",
        "      AnnMap[mask != 0] = 1 # set to 1 only the pixels that corresponds to the mask\n",
        "    \n",
        "      images = torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n",
        "      mask = torch.autograd.Variable(mask, requires_grad=False).to(device) # Load annotation\n",
        "    \n",
        "      Pred = Net(images)['out'] # make prediction     \n",
        "\n",
        "      criterion = torch.nn.CrossEntropyLoss() # Set loss function\n",
        "      Loss=criterion(Pred,mask.long()) # Calculate cross entropy loss      \n",
        "    \n",
        "      val_loss_sum += Loss.data.cpu().numpy()\n",
        "      cont2+=1\n",
        "\n",
        "\n",
        "  delta = 1 - val_loss_sum / val_prev_loss\n",
        "  if(delta >= patience_min_threshold):\n",
        "    val_prev_loss = val_loss_sum\n",
        "    val_last_improvement = 0  \n",
        "  else:\n",
        "    val_last_improvement += 1\n",
        "    if val_last_improvement >= patience_n_iterations:\n",
        "        break  \n",
        "\n",
        "  if(val_loss_sum < val_best_loss ):\n",
        "    val_best_loss  = val_loss_sum\n",
        "    model_weight_name = f'{model_name}_best_{Learning_Rate}'\n",
        "    torch.save(Net.state_dict(), f\"{model_folder}{model_weight_name}.torch\") \n",
        "  \n",
        "  val_loss.append(val_loss_sum/len(val_dataloader))\n",
        "\n",
        "  # Salvando perdas em dataframe\n",
        "  loss_dict['training'].append(train_loss_sum)\n",
        "  loss_dict['validation'].append(val_loss_sum)\n",
        "\n",
        "  # Salvando pesos\n",
        "  model_weight_name = f'{model_name}_{Learning_Rate}'  \n",
        "  torch.save(Net.state_dict(), f\"{model_folder}{model_weight_name}.torch\") \n",
        "\n",
        "  print(f'it = {itr}, training_loss = {train_loss_sum}, val_loss = {val_loss_sum}, delta =  {delta}')\n",
        "# ---- FINALIZANDO TREINO ----- #\n",
        "end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x2V0kyvcxY2h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "9868bf72-2eba-4256-ec0a-92e79ece6557"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-709ca0a461ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Salvando dataframe de métricas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataframe_metrics.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Salvando dataframe de losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "# Salvando dataframe de métricas\n",
        "df_metrics = pd.DataFrame(val_metrics)\n",
        "df_metrics.to_csv('dataframe_metrics.csv', index=False)\n",
        "\n",
        "# Salvando dataframe de losses\n",
        "df_metrics = pd.DataFrame(loss_dict)\n",
        "df_metrics.to_csv('dataframe_losses.csv', index=False)\n",
        "\n",
        "# Duração do treino e validação\n",
        "trainingDuration = time.strftime(\"%H:%M:%S\", time.gmtime((end-start)))\n",
        "print(f\"{trainingDuration} com {n_epochs} épocas\")\n",
        "\n",
        "# Plot de gráfico loss do treino por épocas de treinamento\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "\n",
        "for i in range(n_epochs):\n",
        "  plt.plot(train_loss, color=\"b\", label=\"train\")\n",
        "  plt.plot(val_loss, color=\"g\", label=\"validation\")\n",
        "  plt.legend([\"train\",\"validation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING"
      ],
      "metadata": {
        "id": "VxIwXQq45_4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = f'{model_folder}{model_name}_best_{Learning_Rate}.torch'\n",
        "\n",
        "Net = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)  # Load net\n",
        "Net.classifier[4] = torch.nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))  # Change final layer to 3 classes\n",
        "\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "Net = Net.to(device)  # Set net to GPU or CPU\n",
        "Net.load_state_dict(torch.load(model_path,  map_location=device)) # Load trained model\n",
        "Net.eval() # Set to evaluation mode"
      ],
      "metadata": {
        "id": "68ci_Fiwz0sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(CustomImageDataset(df[df['Status'] == 'Test']), batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "hEH5xMxO6Cfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = {'accuracy': [], 'precision_macro' : [], 'precision_micro' : [], 'recall' : [], \n",
        "               'f1_macro' : [], 'f1_micro' : []}"
      ],
      "metadata": {
        "id": "WuaaRDqPo7ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Net.eval()\n",
        "with torch.no_grad():\n",
        "  # Iterar sobre o dataloader da validação, configurar o batchsize por questões de memória\n",
        "  for images, mask in test_dataloader:\n",
        "    \n",
        "    mask = mask.squeeze()\n",
        "    AnnMap = np.zeros(mask.shape,np.float32)\n",
        "    AnnMap[mask != 0] = 1 # set to 1 only the pixels that corresponds to the mask\n",
        "  \n",
        "    images = torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n",
        "    mask = torch.autograd.Variable(mask, requires_grad=False).to(device) # Load annotation\n",
        "    #print(mask.shape)\n",
        "    Pred = Net(images)['out'] # make prediction\n",
        "\n",
        "    # ---- CALCULANDO MÉTRICAS ----- #\n",
        "    seg = torch.argmax(Pred,1).cpu().detach().numpy()  # Get  prediction classes\n",
        "  \n",
        "    # Accuracy\n",
        "    accuracy = accuracy_score(AnnMap.flatten(), seg.flatten())\n",
        "    # Precision\n",
        "    precision_macro = precision_score(AnnMap.flatten(), seg.flatten(), average='macro')\n",
        "    precision_micro = precision_score(AnnMap.flatten(), seg.flatten(), average='micro')\n",
        "    # Recall:    \n",
        "    recall = recall_score(AnnMap.flatten(), seg.flatten())\n",
        "    # F1\n",
        "    f1_macro = f1_score(AnnMap.flatten(), seg.flatten(), average='macro')\n",
        "    f1_micro = f1_score(AnnMap.flatten(), seg.flatten(), average='micro')    \n",
        "    \n",
        "    # #print(f'Accuracy: {accuracy}, Precision_macro: {precision_macro}, Precision_micro: {precision_micro}, F1_macro: {f1_macro}, F1_micro: {f1_micro}, Recall: {recall}')\n",
        "\n",
        "\n",
        "    test_metrics['accuracy'].append(accuracy)\n",
        "    test_metrics['recall'].append(recall)\n",
        "    test_metrics['precision_macro'].append(precision_macro)\n",
        "    test_metrics['precision_micro'].append(precision_micro)      \n",
        "    test_metrics['f1_macro'].append(f1_macro)\n",
        "    test_metrics['f1_micro'].append(f1_micro)"
      ],
      "metadata": {
        "id": "H1GJzWpm6OL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = pd.DataFrame(test_metrics)"
      ],
      "metadata": {
        "id": "tHx24f5opBnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results.mean(axis=0)"
      ],
      "metadata": {
        "id": "XwNWSAw8pYQ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd9e3238414444188a1a14b954f73269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a4fef251cc4499d8ba87649e98b75b2",
              "IPY_MODEL_cc30bb27a2594fc09a40f0260ee9296b",
              "IPY_MODEL_f0bafad0c8f24fff82f68f1b2bab6c8e"
            ],
            "layout": "IPY_MODEL_e25bd1fb29db46ab8ff6473e1ada8e2c"
          }
        },
        "2a4fef251cc4499d8ba87649e98b75b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9bfe57cb5da466ebe497d1602f7648b",
            "placeholder": "​",
            "style": "IPY_MODEL_7fb704eaf8b44c2ca7fa204319e6cd52",
            "value": "100%"
          }
        },
        "cc30bb27a2594fc09a40f0260ee9296b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bee317ec30d84a5e925a570d25d96cd8",
            "max": 168312152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb7dd525c8744e3d929f231e6f77a083",
            "value": 168312152
          }
        },
        "f0bafad0c8f24fff82f68f1b2bab6c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d625c2dc4624e279cb75396a4e8e5b5",
            "placeholder": "​",
            "style": "IPY_MODEL_a92c759848ba4296a52f2616fd5bd1da",
            "value": " 161M/161M [00:03&lt;00:00, 36.6MB/s]"
          }
        },
        "e25bd1fb29db46ab8ff6473e1ada8e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9bfe57cb5da466ebe497d1602f7648b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb704eaf8b44c2ca7fa204319e6cd52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bee317ec30d84a5e925a570d25d96cd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb7dd525c8744e3d929f231e6f77a083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d625c2dc4624e279cb75396a4e8e5b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92c759848ba4296a52f2616fd5bd1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}