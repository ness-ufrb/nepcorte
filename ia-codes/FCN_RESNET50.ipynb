{"cells":[{"cell_type":"markdown","metadata":{"id":"yvvEPZP_zwa6"},"source":["**Possibilitando acesso a drive**"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"qHM8VHCjUGLR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668435237064,"user_tz":180,"elapsed":33107,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}},"outputId":"5993f4cb-f506-4020-ffb1-933930ed2680"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from google.colab import data_table\n","data_table.enable_dataframe_formatter()"],"metadata":{"id":"-4dBY6sUFX7e","executionInfo":{"status":"ok","timestamp":1668435237064,"user_tz":180,"elapsed":6,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_nabwFGiz5w5"},"source":["**Importando bibliotecas**"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_7C4xX0NUzmL","executionInfo":{"status":"ok","timestamp":1668435240819,"user_tz":180,"elapsed":3760,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"outputs":[],"source":["import os \n","import time\n","import numpy as np \n","import cv2 \n","import torchvision.models.segmentation \n","import torch \n","import torchvision.transforms as tf\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","#import segmentation_models_pytorch as smp\n","import torch.nn as nn\n","import time\n","import pandas as pd\n","import random\n","from torchvision.io import read_image\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","# Segmentation Model\n","#from torchvision.io.image import read_image\n","#from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n","#from torchvision.transforms.functional import to_pil_image\n","\n","# Função de Recall\n","from sklearn.metrics import recall_score\n","# Função de F1\n","from sklearn.metrics import f1_score\n","# Função de Precision\n","from sklearn.metrics import precision_score\n","# Função de Accuracy\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{"id":"Kp9Me-seaoqY"},"source":["**Inicializando constantes**"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"WqFtRtwoIZ8T","executionInfo":{"status":"ok","timestamp":1668435240820,"user_tz":180,"elapsed":6,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"outputs":[],"source":["model_name = 'FCN_RESNET50'\n","model_folder = f'/content/drive/MyDrive/DEV/saved-weights/{model_name}/'\n","\n","ImagesFolder=\"/content/drive/MyDrive/DEV/corte2/\" # ALTERAR ESSE CAMINHO PARA A PASTA CORTE 2 NA NUVEM COM GPUb"]},{"cell_type":"code","source":["n_epochs = 100\n","batchSize = 2 # Esse valor precisa ser divisor do número de imagens no treino\n","batchSize_val = 2 # Esse valor precisa ser divisor do número de imagens na validação\n","Learning_Rate = 1e-5"],"metadata":{"id":"iqvCNFiNmKMn","executionInfo":{"status":"ok","timestamp":1668435240820,"user_tz":180,"elapsed":5,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HY8LXMuAasic"},"source":["**Carregando arquivo com dataframe do dataset \"aleatoriezado\"**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwKoSvj_F4L4","outputId":"01d78549-c381-492e-fcd2-4c703623842c","executionInfo":{"status":"ok","timestamp":1668435242857,"user_tz":180,"elapsed":2042,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Train    640\n","Test      78\n","Val       78\n","Name: Status, dtype: int64"]},"metadata":{},"execution_count":6}],"source":["# Carregando dataframe de um arquivo chamado \"all_dataset_dataframe.csv\"\n","# Referencia https://towardsdatascience.com/how-to-read-csv-file-using-pandas-ab1f5e7e7b58\n","df = pd.read_csv(f'{ImagesFolder}all_dataset_dataframe.csv') # ALTERAR ESSE CAMINHO PARA A LOCALIZAÇÃO DO DATAFRAME NA NUVEM COM GPU\n","df['Status'].value_counts()\n"]},{"cell_type":"markdown","metadata":{"id":"ywxPjkHJbvi_"},"source":["**Lendo valores de desvio padrão e média de um arquivo**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPZIgdYkmREx","outputId":"3bfc47b8-001d-492a-b07e-99a8c2c53208","executionInfo":{"status":"ok","timestamp":1668435244955,"user_tz":180,"elapsed":2101,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.6604449458815983, 0.6988043731738397, 0.6452534234104293]\n","[0.1753238443181036, 0.19331901534376825, 0.1546044630633522]\n"]}],"source":["# Lendo a média e desvio padrão do arquivo \"mean_and_std_list.txt\"\n","mean_and_std_list_file = open(f\"{ImagesFolder}mean_and_std.txt\", \"r\")\n","content_list = mean_and_std_list_file.readlines()\n","\n","mean = [float(integer) for integer in content_list[1].split(' ')[0:3]]\n","std = [float(integer) for integer in content_list[3].split(' ')[0:3]]\n","\n","print(mean)\n","print(std)"]},{"cell_type":"markdown","metadata":{"id":"qnydFlHET-QS"},"source":["**Declaração do Dataset pelo Pytorch**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"sjrWa2An7FgK","executionInfo":{"status":"ok","timestamp":1668435244956,"user_tz":180,"elapsed":16,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"outputs":[],"source":["# Referência: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n","class CustomImageDataset(Dataset):\n","    \n","  def __init__(self, df):\n","    self.dataframe = df\n","    #----------------------------------------------Funções de transformação-------------------------------------------------------------------#\n","    self.transformImg=tf.Compose([tf.ToPILImage(), tf.ToTensor(),tf.Normalize((mean[0], mean[1], mean[2]), (std[0], std[1], std[2]))])\n","    self.transformMask=tf.Compose([tf.ToPILImage(), tf.ToTensor()])\n","\n","  def __len__(self):\n","    return len(self.dataframe)\n","\n","  def __getitem__(self, idx):\n","    pair_path = os.path.join(ImagesFolder,  self.dataframe.iloc[idx].Path)\n","    Img = cv2.imread(os.path.join(pair_path, \"img.png\"))\n","    Label = cv2.imread(os.path.join(pair_path, \"label.png\"),0)\n","\n","    mask = np.zeros(Img.shape[0:2],np.float32)\n","    mask[Label != 0] = 1 # set to 1 only the pixels that corresponds to the mask\n","\n","    image = self.transformImg(Img)\n","    label = self.transformMask(mask)\n","    return image, label"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"lrUgP-UOOQFf","executionInfo":{"status":"ok","timestamp":1668435244956,"user_tz":180,"elapsed":15,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"outputs":[],"source":["ds_train=CustomImageDataset(df[df['Status'] == 'Train'])\n","ds_val=CustomImageDataset(df[df['Status'] == 'Val'])"]},{"cell_type":"code","source":["print(len(ds_train))\n","print(len(ds_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fim9P8bay_Ga","executionInfo":{"status":"ok","timestamp":1668435244956,"user_tz":180,"elapsed":14,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}},"outputId":"3ce70f77-348c-42dc-8eac-d21dfa12bad0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["640\n","78\n"]}]},{"cell_type":"markdown","metadata":{"id":"4Fa0qK2VULgJ"},"source":["**Instanciação do DataLoader's pelo Pytorch**"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Xi_buGBPQ1Jd","executionInfo":{"status":"ok","timestamp":1668435244957,"user_tz":180,"elapsed":13,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"outputs":[],"source":["train_dataloader = DataLoader(ds_train, batch_size=batchSize, shuffle=True)\n","val_dataloader = DataLoader(ds_val, batch_size=batchSize_val, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"GK6z-HMjUclc"},"source":[" **Definição da estrutura FCN_RESNET50**\n"]},{"cell_type":"markdown","metadata":{"id":"vsaE6vAic3wN"},"source":[" Referência: https://pytorch.org/vision/stable/models/generated/torchvision.models.segmentation.fcn_resnet50.html#torchvision.models.segmentation.FCN_ResNet50_Weights"]},{"cell_type":"markdown","source":["# MODEL"],"metadata":{"id":"0PLB8GVLNg7d"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["c985757354af4569999b58755af606bd","e887375e46d842f69e55c0e8e879fefc","d084467971684a858f381bdb3a3bf630","ae54ee236a054d5ba02e7b0e679c6c12","d70fccad8a2c4069bf940eb5b2ffee29","257fb86be65a4adb89bf98bc3e6b2c85","002ef5b2db964e6cb19a8f0951d727c7","6edf8970882f4e03a044e51ba694c491","f32ffafaf02545ca8bd623952c93a57d","9a379f8cc0bf470d8afa8c7ab9e1bab8","6facf9f589f24a90a9af23d7197b9470"]},"id":"_AwKg3JNPVX5","outputId":"a58d1287-f5c0-4659-8788-10493211e227","executionInfo":{"status":"ok","timestamp":1668435246896,"user_tz":180,"elapsed":1951,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=FCN_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=FCN_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fcn_resnet50_coco-1167a1af.pth\" to /root/.cache/torch/hub/checkpoints/fcn_resnet50_coco-1167a1af.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/135M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c985757354af4569999b58755af606bd"}},"metadata":{}}],"source":["#--------------Load and set net and optimizer-------------------------------------\n","Net = torchvision.models.segmentation.fcn_resnet50(pretrained=True) # Load net\n","Net.classifier[4] = torch.nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1)) # Change final layer to 2 classes"]},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","Net=Net.to(device)\n","optimizer=torch.optim.Adam(params=Net.parameters(),lr=Learning_Rate) # Create adam optimizer"],"metadata":{"id":"dfbE59OiNzRV","executionInfo":{"status":"ok","timestamp":1668435249630,"user_tz":180,"elapsed":2737,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ftzhro928ZzG"},"source":["**Treinamento**"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"BxHqvnR-P5-A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668449065899,"user_tz":180,"elapsed":13816287,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}},"outputId":"fe05372d-9bb0-4f17-f240-40c5d6a9b704"},"outputs":[{"output_type":"stream","name":"stdout","text":["training epoch: 0\n","it = 0, training_loss = 67.45706796646118, val_loss = 4.21977823227644, delta =  1.0\n","training epoch: 1\n","it = 1, training_loss = 28.991478361189365, val_loss = 3.159600928425789, delta =  0.251240052318749\n","training epoch: 2\n","it = 2, training_loss = 21.866487573832273, val_loss = 2.58975725248456, delta =  0.18035305370831833\n","training epoch: 3\n","it = 3, training_loss = 17.053805846720934, val_loss = 1.9843834973871708, delta =  0.23375694942705771\n","training epoch: 4\n","it = 4, training_loss = 13.563868187367916, val_loss = 1.709451075643301, delta =  0.1385480286980173\n","training epoch: 5\n","it = 5, training_loss = 11.008127374574542, val_loss = 1.4629394374787807, delta =  0.14420514378965366\n","training epoch: 6\n","it = 6, training_loss = 9.788583567366004, val_loss = 1.3228224273771048, delta =  0.09577772429400944\n","training epoch: 7\n","it = 7, training_loss = 8.113522676751018, val_loss = 1.1367728412151337, delta =  0.1406459267030048\n","training epoch: 8\n","it = 8, training_loss = 6.681260300800204, val_loss = 0.9911477975547314, delta =  0.1281039081693216\n","training epoch: 9\n","it = 9, training_loss = 5.721239336766303, val_loss = 0.9425977747887373, delta =  0.04898363582683851\n","training epoch: 10\n","it = 10, training_loss = 5.009366514161229, val_loss = 0.8832554519176483, delta =  0.06295614572651553\n","training epoch: 11\n","it = 11, training_loss = 4.418619600124657, val_loss = 0.8705023601651192, delta =  0.01443873539058349\n","training epoch: 12\n","it = 12, training_loss = 3.923363434150815, val_loss = 0.8439622819423676, delta =  0.03048823235553022\n","training epoch: 13\n","it = 13, training_loss = 3.6208638306707144, val_loss = 0.8533653561025858, delta =  -0.011141581041485882\n","training epoch: 14\n","it = 14, training_loss = 3.156029289588332, val_loss = 0.850333328358829, delta =  -0.0075489705556492925\n","training epoch: 15\n","it = 15, training_loss = 2.8407953227870166, val_loss = 0.8518782174214721, delta =  -0.009379489638904337\n","training epoch: 16\n","it = 16, training_loss = 2.538018675055355, val_loss = 0.8426250973716378, delta =  0.0015844127152842002\n","training epoch: 17\n","it = 17, training_loss = 2.3234578343108296, val_loss = 0.8331881631165743, delta =  0.012766114145524088\n","training epoch: 18\n","it = 18, training_loss = 2.109695167746395, val_loss = 0.8394709154963493, delta =  -0.007540616463241889\n","training epoch: 19\n","it = 19, training_loss = 1.9270730228163302, val_loss = 0.9230581629090011, delta =  -0.10786278990842169\n","training epoch: 20\n","it = 20, training_loss = 1.795917873736471, val_loss = 0.8929013032466173, delta =  -0.07166825307105129\n","training epoch: 21\n","it = 21, training_loss = 1.6471518743783236, val_loss = 0.9674671208485961, delta =  -0.16116282452903063\n","training epoch: 22\n"]}],"source":["epoch = []\n","\n","train_loss = []\n","train_loss_sum = 0\n","\n","val_loss = []\n","val_loss_sum = 0\n","\n","cont2 = 0\n","\n","val_metrics = {'accuracy': [], 'precision_macro' : [], 'precision_micro' : [], 'recall' : [], \n","               'f1_macro' : [], 'f1_micro' : [], 'training_loss' : [], 'validation_loss' : []}\n","loss_dict = {'training' : [], 'validation' : []} \n","\n","train_prev_loss = float('-inf')\n","train_best_loss = float('inf')\n","train_last_improvement = 0\n","\n","\n","val_prev_loss = float('-inf')\n","val_best_loss = float('inf')\n","val_last_improvement = 0\n","\n","patience_n_iterations = 5\n","patience_min_threshold = 0.01\n","\n","\n","#Net.load_state_dict(torch.load(\"0.torch\")) # Load trained model\n","start = time.time()\n","for itr in range(n_epochs): # Training loop\n","  print(f'training epoch: {itr}')\n","  batch_it = 0\n","  train_loss_sum = 0\n","  \n","  #TRAINING\n","  Net.train()\n","  for images, mask in train_dataloader:\n","    Net.zero_grad()\n","    \n","    # Iterar sobre o dataloader do treino    \n","    mask = mask.squeeze()\n","    images = torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n","    mask = torch.autograd.Variable(mask, requires_grad=False).to(device) # Load annotation\n","    \n","    Pred=Net(images)['out'] # make prediction\n","    \n","    criterion = torch.nn.CrossEntropyLoss() # Set loss function\n","    \n","    Loss = criterion(Pred,mask.long()) # Calculate cross entropy loss    \n","    Loss.backward() # Backpropogate loss\n","    optimizer.step() # Apply gradient descent change to weight\n","    \n","    #print(f'Training Batch Iteration = {batch_it}, Training Loss = {Loss.data.cpu().numpy()}')\n","    train_loss_sum += Loss.data.cpu().numpy()\n","    batch_it += 1\n","    \n","  delta = 1 - train_loss_sum / train_prev_loss\n","  if(delta >= patience_min_threshold):\n","    train_prev_loss = train_loss_sum\n","    train_last_improvement = 0  \n","  else:\n","    train_last_improvement += 1\n","    if train_last_improvement >= patience_n_iterations:\n","        break\n","  \n","  train_loss.append(train_loss_sum/len(train_dataloader))\n","\n","  #VALIDATION \n","  val_loss_sum = 0\n","\n","  Net.eval()\n","  with torch.no_grad():\n","        \n","    for images, mask in val_dataloader:\n","        \n","      mask = mask.squeeze()\n","      AnnMap = np.zeros(mask.shape,np.float32)\n","      AnnMap[mask != 0] = 1 # set to 1 only the pixels that corresponds to the mask\n","    \n","      images = torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n","      mask = torch.autograd.Variable(mask, requires_grad=False).to(device) # Load annotation\n","    \n","      Pred = Net(images)['out'] # make prediction     \n","\n","      criterion = torch.nn.CrossEntropyLoss() # Set loss function\n","      Loss=criterion(Pred,mask.long()) # Calculate cross entropy loss      \n","    \n","      val_loss_sum += Loss.data.cpu().numpy()\n","      cont2+=1\n","\n","\n","  delta = 1 - val_loss_sum / val_prev_loss\n","  if(delta >= patience_min_threshold):\n","    val_prev_loss = val_loss_sum\n","    val_last_improvement = 0  \n","  else:\n","    val_last_improvement += 1\n","    if val_last_improvement >= patience_n_iterations:\n","        break  \n","\n","  if(val_loss_sum < val_best_loss ):\n","    val_best_loss  = val_loss_sum\n","    model_weight_name = f'{model_name}_best_{Learning_Rate}'\n","    torch.save(Net.state_dict(), f\"{model_folder}{model_weight_name}.torch\") \n","  \n","  val_loss.append(val_loss_sum/len(val_dataloader))\n","\n","  # Salvando perdas em dataframe\n","  loss_dict['training'].append(train_loss_sum)\n","  loss_dict['validation'].append(val_loss_sum)\n","\n","  # Salvando pesos\n","  model_weight_name = f'{model_name}_{Learning_Rate}'  \n","  torch.save(Net.state_dict(), f\"{model_folder}{model_weight_name}.torch\") \n","\n","  print(f'it = {itr}, training_loss = {train_loss_sum}, val_loss = {val_loss_sum}, delta =  {delta}')\n","# ---- FINALIZANDO TREINO ----- #\n","end = time.time()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"x2V0kyvcxY2h","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"ok","timestamp":1668449066517,"user_tz":180,"elapsed":626,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}},"outputId":"b42307c3-8757-40dd-956e-9aca342e6c72"},"outputs":[{"output_type":"stream","name":"stdout","text":["03:50:16 com 100 épocas\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Salvando dataframe de métricas\n","df_metrics = pd.DataFrame(val_metrics)\n","df_metrics.to_csv('dataframe_metrics.csv', index=False)\n","\n","# Duração do treino e validação\n","trainingDuration = time.strftime(\"%H:%M:%S\", time.gmtime((end-start)))\n","print(f\"{trainingDuration} com {n_epochs} épocas\")\n","\n","# Plot de gráfico loss do treino por épocas de treinamento\n","plt.title(\"Model Loss\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","\n","for i in range(n_epochs):\n","  plt.plot(train_loss, color=\"b\", label=\"train\")\n","  plt.plot(val_loss, color=\"g\", label=\"validation\")\n","  plt.legend([\"train\",\"validation\"])"]},{"cell_type":"markdown","source":["# TESTING"],"metadata":{"id":"VxIwXQq45_4C"}},{"cell_type":"code","source":["model_path = f'{model_folder}{model_name}_best_{Learning_Rate}.torch'\n","\n","Net = torchvision.models.segmentation.fcn_resnet50(pretrained=True)  # Load net\n","Net.classifier[4] = torch.nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))  # Change final layer to 3 classes\n","\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","Net = Net.to(device)  # Set net to GPU or CPU\n","Net.load_state_dict(torch.load(model_path,  map_location=device)) # Load trained model\n","Net.eval() # Set to evaluation mode"],"metadata":{"id":"68ci_Fiwz0sB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668449068178,"user_tz":180,"elapsed":1666,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}},"outputId":"b05616a7-3348-4ef1-e80b-622bed7b29c9"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FCN(\n","  (backbone): IntermediateLayerGetter(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (classifier): FCNHead(\n","    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.1, inplace=False)\n","    (4): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (aux_classifier): FCNHead(\n","    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.1, inplace=False)\n","    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["test_dataloader = DataLoader(CustomImageDataset(df[df['Status'] == 'Test']), batch_size=1, shuffle=False)"],"metadata":{"id":"hEH5xMxO6Cfy","executionInfo":{"status":"ok","timestamp":1668449068178,"user_tz":180,"elapsed":5,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["test_metrics = {'accuracy': [], 'precision_macro' : [], 'precision_micro' : [], 'recall' : [], \n","               'f1_macro' : [], 'f1_micro' : []}"],"metadata":{"id":"WuaaRDqPo7ml","executionInfo":{"status":"ok","timestamp":1668449068179,"user_tz":180,"elapsed":4,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["Net.eval()\n","with torch.no_grad():\n","  # Iterar sobre o dataloader da validação, configurar o batchsize por questões de memória\n","  for images, mask in test_dataloader:\n","    \n","    mask = mask.squeeze()\n","    AnnMap = np.zeros(mask.shape,np.float32)\n","    AnnMap[mask != 0] = 1 # set to 1 only the pixels that corresponds to the mask\n","  \n","    images = torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n","    mask = torch.autograd.Variable(mask, requires_grad=False).to(device) # Load annotation\n","    #print(mask.shape)\n","    Pred = Net(images)['out'] # make prediction\n","\n","    # ---- CALCULANDO MÉTRICAS ----- #\n","    seg = torch.argmax(Pred,1).cpu().detach().numpy()  # Get  prediction classes\n","  \n","    # Accuracy\n","    accuracy = accuracy_score(AnnMap.flatten(), seg.flatten())\n","    # Precision\n","    precision_macro = precision_score(AnnMap.flatten(), seg.flatten(), average='macro')\n","    precision_micro = precision_score(AnnMap.flatten(), seg.flatten(), average='micro')\n","    # Recall:    \n","    recall = recall_score(AnnMap.flatten(), seg.flatten())\n","    # F1\n","    f1_macro = f1_score(AnnMap.flatten(), seg.flatten(), average='macro')\n","    f1_micro = f1_score(AnnMap.flatten(), seg.flatten(), average='micro')    \n","    \n","    # #print(f'Accuracy: {accuracy}, Precision_macro: {precision_macro}, Precision_micro: {precision_micro}, F1_macro: {f1_macro}, F1_micro: {f1_micro}, Recall: {recall}')\n","\n","\n","    test_metrics['accuracy'].append(accuracy)\n","    test_metrics['recall'].append(recall)\n","    test_metrics['precision_macro'].append(precision_macro)\n","    test_metrics['precision_micro'].append(precision_micro)      \n","    test_metrics['f1_macro'].append(f1_macro)\n","    test_metrics['f1_micro'].append(f1_micro)"],"metadata":{"id":"H1GJzWpm6OL5","executionInfo":{"status":"ok","timestamp":1668449482689,"user_tz":180,"elapsed":414514,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["test_results = pd.DataFrame(test_metrics)"],"metadata":{"id":"tHx24f5opBnU","executionInfo":{"status":"ok","timestamp":1668449482690,"user_tz":180,"elapsed":21,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["test_results.mean(axis=0)"],"metadata":{"id":"XwNWSAw8pYQ5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668449482690,"user_tz":180,"elapsed":20,"user":{"displayName":"Ramon Pereira Lopes","userId":"12906320949961501461"}},"outputId":"f559a370-94da-42b9-c8ae-4bb1b984d4d0"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["accuracy           0.994387\n","precision_macro    0.983736\n","precision_micro    0.994387\n","recall             0.957435\n","f1_macro           0.979325\n","f1_micro           0.994387\n","dtype: float64"]},"metadata":{},"execution_count":21}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"c985757354af4569999b58755af606bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e887375e46d842f69e55c0e8e879fefc","IPY_MODEL_d084467971684a858f381bdb3a3bf630","IPY_MODEL_ae54ee236a054d5ba02e7b0e679c6c12"],"layout":"IPY_MODEL_d70fccad8a2c4069bf940eb5b2ffee29"}},"e887375e46d842f69e55c0e8e879fefc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_257fb86be65a4adb89bf98bc3e6b2c85","placeholder":"​","style":"IPY_MODEL_002ef5b2db964e6cb19a8f0951d727c7","value":"100%"}},"d084467971684a858f381bdb3a3bf630":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6edf8970882f4e03a044e51ba694c491","max":141567418,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f32ffafaf02545ca8bd623952c93a57d","value":141567418}},"ae54ee236a054d5ba02e7b0e679c6c12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a379f8cc0bf470d8afa8c7ab9e1bab8","placeholder":"​","style":"IPY_MODEL_6facf9f589f24a90a9af23d7197b9470","value":" 135M/135M [00:00&lt;00:00, 251MB/s]"}},"d70fccad8a2c4069bf940eb5b2ffee29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"257fb86be65a4adb89bf98bc3e6b2c85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"002ef5b2db964e6cb19a8f0951d727c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6edf8970882f4e03a044e51ba694c491":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f32ffafaf02545ca8bd623952c93a57d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a379f8cc0bf470d8afa8c7ab9e1bab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6facf9f589f24a90a9af23d7197b9470":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}