{"cells":[{"cell_type":"markdown","metadata":{"id":"yvvEPZP_zwa6"},"source":["**Possibilitando acesso a drive**"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"qHM8VHCjUGLR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668008594336,"user_tz":180,"elapsed":51663,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}},"outputId":"15066552-62b5-42a1-805a-6722106f6973"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from google.colab import data_table\n","data_table.enable_dataframe_formatter()"],"metadata":{"id":"-4dBY6sUFX7e","executionInfo":{"status":"ok","timestamp":1668008594340,"user_tz":180,"elapsed":30,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_nabwFGiz5w5"},"source":["**Importando bibliotecas**"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_7C4xX0NUzmL","executionInfo":{"status":"ok","timestamp":1668008597613,"user_tz":180,"elapsed":3298,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"outputs":[],"source":["import os \n","import time\n","import numpy as np \n","import cv2 \n","import torchvision.models.segmentation \n","import torch \n","import torchvision.transforms as tf\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","#import segmentation_models_pytorch as smp\n","import torch.nn as nn\n","import time\n","import pandas as pd\n","import random\n","from torchvision.io import read_image\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","# Segmentation Model\n","#from torchvision.io.image import read_image\n","#from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n","#from torchvision.transforms.functional import to_pil_image\n","\n","# Função de Recall\n","from sklearn.metrics import recall_score\n","# Função de F1\n","from sklearn.metrics import f1_score\n","# Função de Precision\n","from sklearn.metrics import precision_score\n","# Função de Accuracy\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{"id":"Kp9Me-seaoqY"},"source":["**Inicializando constantes**"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"WqFtRtwoIZ8T","executionInfo":{"status":"ok","timestamp":1668008597614,"user_tz":180,"elapsed":17,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"outputs":[],"source":["model_name = 'MOBILENET_V3_LARGE'\n","model_folder = f'/content/drive/MyDrive/DEV/saved-weights/{model_name}/'\n","\n","ImagesFolder=\"/content/drive/MyDrive/DEV/corte2/\" # ALTERAR ESSE CAMINHO PARA A PASTA CORTE 2 NA NUVEM COM GPUb"]},{"cell_type":"code","source":["n_epochs = 100\n","batchSize = 2 # Esse valor precisa ser divisor do número de imagens no treino\n","batchSize_val = 2 # Esse valor precisa ser divisor do número de imagens na validação\n","Learning_Rate = 1e-5"],"metadata":{"id":"iqvCNFiNmKMn","executionInfo":{"status":"ok","timestamp":1668008597616,"user_tz":180,"elapsed":15,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HY8LXMuAasic"},"source":["**Carregando arquivo com dataframe do dataset \"aleatoriezado\"**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwKoSvj_F4L4","outputId":"888991f6-9cc6-4057-a744-8a1a4d5e28e8","executionInfo":{"status":"ok","timestamp":1668008598873,"user_tz":180,"elapsed":1270,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Train    640\n","Test      78\n","Val       78\n","Name: Status, dtype: int64"]},"metadata":{},"execution_count":6}],"source":["# Carregando dataframe de um arquivo chamado \"all_dataset_dataframe.csv\"\n","# Referencia https://towardsdatascience.com/how-to-read-csv-file-using-pandas-ab1f5e7e7b58\n","df = pd.read_csv(f'{ImagesFolder}all_dataset_dataframe.csv') # ALTERAR ESSE CAMINHO PARA A LOCALIZAÇÃO DO DATAFRAME NA NUVEM COM GPU\n","df['Status'].value_counts()\n"]},{"cell_type":"markdown","metadata":{"id":"ywxPjkHJbvi_"},"source":["**Lendo valores de desvio padrão e média de um arquivo**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CPZIgdYkmREx","outputId":"45378e58-f3f2-452d-ff6b-a6193e3846ae","executionInfo":{"status":"ok","timestamp":1668008599463,"user_tz":180,"elapsed":597,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.6604449458815983, 0.6988043731738397, 0.6452534234104293]\n","[0.1753238443181036, 0.19331901534376825, 0.1546044630633522]\n"]}],"source":["# Lendo a média e desvio padrão do arquivo \"mean_and_std_list.txt\"\n","mean_and_std_list_file = open(f\"{ImagesFolder}mean_and_std.txt\", \"r\")\n","content_list = mean_and_std_list_file.readlines()\n","\n","mean = [float(integer) for integer in content_list[1].split(' ')[0:3]]\n","std = [float(integer) for integer in content_list[3].split(' ')[0:3]]\n","\n","print(mean)\n","print(std)"]},{"cell_type":"markdown","metadata":{"id":"qnydFlHET-QS"},"source":["**Declaração do Dataset pelo Pytorch**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"sjrWa2An7FgK","executionInfo":{"status":"ok","timestamp":1668008599464,"user_tz":180,"elapsed":29,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"outputs":[],"source":["# Referência: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n","class CustomImageDataset(Dataset):\n","    \n","  def __init__(self, df):\n","    self.dataframe = df\n","    #----------------------------------------------Funções de transformação-------------------------------------------------------------------#\n","    self.transformImg=tf.Compose([tf.ToPILImage(), tf.ToTensor(),tf.Normalize((mean[0], mean[1], mean[2]), (std[0], std[1], std[2]))])\n","    self.transformMask=tf.Compose([tf.ToPILImage(), tf.ToTensor()])\n","\n","  def __len__(self):\n","    return len(self.dataframe)\n","\n","  def __getitem__(self, idx):\n","    pair_path = os.path.join(ImagesFolder,  self.dataframe.iloc[idx].Path)\n","    Img = cv2.imread(os.path.join(pair_path, \"img.png\"))\n","    Label = cv2.imread(os.path.join(pair_path, \"label.png\"),0)\n","\n","    mask = np.zeros(Img.shape[0:2],np.float32)\n","    mask[Label != 0] = 1 # set to 1 only the pixels that corresponds to the mask\n","\n","    image = self.transformImg(Img)\n","    label = self.transformMask(mask)\n","    return image, label"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"lrUgP-UOOQFf","executionInfo":{"status":"ok","timestamp":1668008599466,"user_tz":180,"elapsed":29,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"outputs":[],"source":["ds_train=CustomImageDataset(df[df['Status'] == 'Train'])\n","ds_val=CustomImageDataset(df[df['Status'] == 'Val'])"]},{"cell_type":"code","source":["print(len(ds_train))\n","print(len(ds_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fim9P8bay_Ga","executionInfo":{"status":"ok","timestamp":1668008599467,"user_tz":180,"elapsed":27,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}},"outputId":"fe7b92ec-1ce9-43d6-8986-1164c3d6f985"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["640\n","78\n"]}]},{"cell_type":"markdown","metadata":{"id":"4Fa0qK2VULgJ"},"source":["**Instanciação do DataLoader's pelo Pytorch**"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Xi_buGBPQ1Jd","executionInfo":{"status":"ok","timestamp":1668008599468,"user_tz":180,"elapsed":22,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"outputs":[],"source":["train_dataloader = DataLoader(ds_train, batch_size=batchSize, shuffle=True, num_workers=2)\n","val_dataloader = DataLoader(ds_val, batch_size=batchSize_val, shuffle=True, num_workers=2)"]},{"cell_type":"markdown","source":["# MODEL\n","\n"],"metadata":{"id":"0PLB8GVLNg7d"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"_AwKg3JNPVX5","colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["b5bb342c42f5423bb066d55585b6b99d","9d87e6eb180d4a0d921761f06243c8b0","e211ce52b5b84f399e13f5859eec634f","b4590a7e175d419f9cab3ce9f3d8bee7","cf02a7ead714498a8de5a14d1d933f3a","e3451b7664e847ee9e559aefe028e673","bccb09acb21e45889a26d16b5e27bde5","aeb98741145a45a88463e3b3d6290c56","dc1324c637bb4426b98c30237e616050","f74965bf97d54d498456f9471e9132d7","0923df46111e4878957d63730f87cfea"]},"executionInfo":{"status":"ok","timestamp":1668008600573,"user_tz":180,"elapsed":1125,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}},"outputId":"fd220a2f-b7ea-4f96-c077-90f6ab9555ba"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DeepLabV3_MobileNet_V3_Large_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/deeplabv3_mobilenet_v3_large-fc3c493d.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_mobilenet_v3_large-fc3c493d.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/42.3M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5bb342c42f5423bb066d55585b6b99d"}},"metadata":{}}],"source":["Net = torchvision.models.segmentation.deeplabv3_mobilenet_v3_large(pretrained=True) # Load net\n","Net.classifier[4] = torch.nn.Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1)) # Change final layer to 3 classes"]},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","Net=Net.to(device)\n","optimizer=torch.optim.Adam(params=Net.parameters(),lr=Learning_Rate) # Create adam optimizer"],"metadata":{"id":"t15joua4N7ut","executionInfo":{"status":"ok","timestamp":1668008604153,"user_tz":180,"elapsed":3587,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ftzhro928ZzG"},"source":["**Treinamento**"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"BxHqvnR-P5-A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668011130395,"user_tz":180,"elapsed":2526262,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}},"outputId":"3c8f2434-e9dc-4638-ca15-c437d174a70d"},"outputs":[{"output_type":"stream","name":"stdout","text":["training epoch: 0\n","it = 0, training_loss = 132.42273113131523, val_loss = 8.59610941261053, delta =  1.0\n","training epoch: 1\n","it = 1, training_loss = 46.659806095063686, val_loss = 5.093841060996056, delta =  0.40742482249895884\n","training epoch: 2\n","it = 2, training_loss = 33.62512049078941, val_loss = 3.9468337446451187, delta =  0.2251753249887718\n","training epoch: 3\n","it = 3, training_loss = 26.00225780531764, val_loss = 3.232054367661476, delta =  0.18110197267706607\n","training epoch: 4\n","it = 4, training_loss = 21.04152050241828, val_loss = 2.574558086693287, delta =  0.20342983321902308\n","training epoch: 5\n","it = 5, training_loss = 17.37377967312932, val_loss = 2.1873444616794586, delta =  0.15040003448170713\n","training epoch: 6\n","it = 6, training_loss = 14.778932120651007, val_loss = 1.9116455912590027, delta =  0.12604273138066802\n","training epoch: 7\n","it = 7, training_loss = 12.802122917026281, val_loss = 1.7087589707225561, delta =  0.10613192187095\n","training epoch: 8\n","it = 8, training_loss = 11.177771616727114, val_loss = 1.5491907019168139, delta =  0.09338254928854484\n","training epoch: 9\n","it = 9, training_loss = 9.909090550616384, val_loss = 1.3753325436264277, delta =  0.11222514960570795\n","training epoch: 10\n","it = 10, training_loss = 8.895271949470043, val_loss = 1.2638590168207884, delta =  0.08105205342680966\n","training epoch: 11\n","it = 11, training_loss = 8.031321782618761, val_loss = 1.1686968859285116, delta =  0.07529489415018387\n","training epoch: 12\n","it = 12, training_loss = 7.261570928618312, val_loss = 1.1462848596274853, delta =  0.01917693678392951\n","training epoch: 13\n","it = 13, training_loss = 6.6959433211013675, val_loss = 1.087662672623992, delta =  0.051141028786286236\n","training epoch: 14\n","it = 14, training_loss = 6.135725414380431, val_loss = 1.021685660816729, delta =  0.060659442920931506\n","training epoch: 15\n","it = 15, training_loss = 5.642295469529927, val_loss = 1.02442027349025, delta =  -0.0026765694952937125\n","training epoch: 16\n","it = 16, training_loss = 5.24289936106652, val_loss = 0.9493271326646209, delta =  0.07082269129065122\n","training epoch: 17\n","it = 17, training_loss = 4.927855981513858, val_loss = 0.9557434199377894, delta =  -0.006758773717084221\n","training epoch: 18\n","it = 18, training_loss = 4.624825354665518, val_loss = 0.946581669151783, delta =  0.00289200994933303\n","training epoch: 19\n","it = 19, training_loss = 4.291854538954794, val_loss = 0.9012162378057837, delta =  0.05067894217222779\n","training epoch: 20\n","it = 20, training_loss = 4.031169459223747, val_loss = 0.8966492312029004, delta =  0.00506760354651703\n","training epoch: 21\n","it = 21, training_loss = 3.8244084110483527, val_loss = 0.8955465946346521, delta =  0.006291101883534211\n","training epoch: 22\n","it = 22, training_loss = 3.639353529550135, val_loss = 0.8539973357692361, delta =  0.05239464188030263\n","training epoch: 23\n","it = 23, training_loss = 3.4164179172366858, val_loss = 0.8682137653231621, delta =  -0.016646924947512298\n","training epoch: 24\n","it = 24, training_loss = 3.2775062317959964, val_loss = 0.8269034484401345, delta =  0.031725962358766346\n","training epoch: 25\n","it = 25, training_loss = 3.103091503493488, val_loss = 0.88249630946666, delta =  -0.06723017195223391\n","training epoch: 26\n","it = 26, training_loss = 2.981096914038062, val_loss = 0.8469022000208497, delta =  -0.024185110871699278\n","training epoch: 27\n","it = 27, training_loss = 2.899793202523142, val_loss = 0.8891639802604914, delta =  -0.07529359314900042\n","training epoch: 28\n","it = 28, training_loss = 2.7699274024926126, val_loss = 0.8495550639927387, delta =  -0.02739330159444142\n","training epoch: 29\n"]}],"source":["epoch = []\n","\n","train_loss = []\n","train_loss_sum = 0\n","\n","val_loss = []\n","val_loss_sum = 0\n","\n","cont2 = 0\n","\n","val_metrics = {'accuracy': [], 'precision_macro' : [], 'precision_micro' : [], 'recall' : [], \n","               'f1_macro' : [], 'f1_micro' : [], 'training_loss' : [], 'validation_loss' : []}\n","loss_dict = {'training' : [], 'validation' : []} \n","\n","train_prev_loss = float('-inf')\n","train_best_loss = float('inf')\n","train_last_improvement = 0\n","\n","\n","val_prev_loss = float('-inf')\n","val_best_loss = float('inf')\n","val_last_improvement = 0\n","\n","patience_n_iterations = 5\n","patience_min_threshold = 0.01\n","\n","\n","#Net.load_state_dict(torch.load(\"0.torch\")) # Load trained model\n","start = time.time()\n","for itr in range(n_epochs): # Training loop\n","  print(f'training epoch: {itr}')\n","  batch_it = 0\n","  train_loss_sum = 0\n","  \n","  #TRAINING\n","  Net.train()\n","  for images, mask in train_dataloader:\n","    Net.zero_grad()\n","    \n","    # Iterar sobre o dataloader do treino    \n","    mask = mask.squeeze()\n","    images = torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n","    mask = torch.autograd.Variable(mask, requires_grad=False).to(device) # Load annotation\n","    \n","    Pred=Net(images)['out'] # make prediction\n","    \n","    criterion = torch.nn.CrossEntropyLoss() # Set loss function\n","    \n","    Loss = criterion(Pred,mask.long()) # Calculate cross entropy loss    \n","    Loss.backward() # Backpropogate loss\n","    optimizer.step() # Apply gradient descent change to weight\n","    \n","    #print(f'Training Batch Iteration = {batch_it}, Training Loss = {Loss.data.cpu().numpy()}')\n","    train_loss_sum += Loss.data.cpu().numpy()\n","    batch_it += 1\n","    \n","  delta = 1 - train_loss_sum / train_prev_loss\n","  if(delta >= patience_min_threshold):\n","    train_prev_loss = train_loss_sum\n","    train_last_improvement = 0  \n","  else:\n","    train_last_improvement += 1\n","    if train_last_improvement >= patience_n_iterations:\n","        break\n","  \n","  train_loss.append(train_loss_sum/len(train_dataloader))\n","\n","  #VALIDATION \n","  val_loss_sum = 0\n","\n","  Net.eval()\n","  with torch.no_grad():\n","        \n","    for images, mask in val_dataloader:\n","        \n","      mask = mask.squeeze()\n","      AnnMap = np.zeros(mask.shape,np.float32)\n","      AnnMap[mask != 0] = 1 # set to 1 only the pixels that corresponds to the mask\n","    \n","      images = torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n","      mask = torch.autograd.Variable(mask, requires_grad=False).to(device) # Load annotation\n","    \n","      Pred = Net(images)['out'] # make prediction     \n","\n","      criterion = torch.nn.CrossEntropyLoss() # Set loss function\n","      Loss=criterion(Pred,mask.long()) # Calculate cross entropy loss      \n","    \n","      val_loss_sum += Loss.data.cpu().numpy()\n","      cont2+=1\n","\n","\n","  delta = 1 - val_loss_sum / val_prev_loss\n","  if(delta >= patience_min_threshold):\n","    val_prev_loss = val_loss_sum\n","    val_last_improvement = 0  \n","  else:\n","    val_last_improvement += 1\n","    if val_last_improvement >= patience_n_iterations:\n","        break  \n","\n","  if(val_loss_sum < val_best_loss ):\n","    val_best_loss  = val_loss_sum\n","    model_weight_name = f'{model_name}_best_{Learning_Rate}'\n","    torch.save(Net.state_dict(), f\"{model_folder}{model_weight_name}.torch\") \n","  \n","  val_loss.append(val_loss_sum/len(val_dataloader))\n","\n","  # Salvando perdas em dataframe\n","  loss_dict['training'].append(train_loss_sum)\n","  loss_dict['validation'].append(val_loss_sum)\n","\n","  # Salvando pesos\n","  model_weight_name = f'{model_name}_{Learning_Rate}'  \n","  torch.save(Net.state_dict(), f\"{model_folder}{model_weight_name}.torch\") \n","\n","  print(f'it = {itr}, training_loss = {train_loss_sum}, val_loss = {val_loss_sum}, delta =  {delta}')\n","# ---- FINALIZANDO TREINO ----- #\n","end = time.time()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"x2V0kyvcxY2h","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"ok","timestamp":1668011130959,"user_tz":180,"elapsed":585,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}},"outputId":"f5a410f1-06fa-4755-a386-998cded022dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["00:42:05 com 100 épocas\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Salvando dataframe de métricas\n","df_metrics = pd.DataFrame(val_metrics)\n","df_metrics.to_csv('dataframe_metrics.csv', index=False)\n","\n","# Duração do treino e validação\n","trainingDuration = time.strftime(\"%H:%M:%S\", time.gmtime((end-start)))\n","print(f\"{trainingDuration} com {n_epochs} épocas\")\n","\n","# Plot de gráfico loss do treino por épocas de treinamento\n","plt.title(\"Model Loss\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","\n","for i in range(n_epochs):\n","  plt.plot(train_loss, color=\"b\", label=\"train\")\n","  plt.plot(val_loss, color=\"g\", label=\"validation\")\n","  plt.legend([\"train\",\"validation\"])"]},{"cell_type":"markdown","source":["# TESTING"],"metadata":{"id":"VxIwXQq45_4C"}},{"cell_type":"code","source":["model_path = f'{model_folder}{model_name}_best_{Learning_Rate}.torch'\n","\n","Net = torchvision.models.segmentation.deeplabv3_mobilenet_v3_large(pretrained=True) # Load net\n","Net.classifier[4] = torch.nn.Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1)) # Change final layer to 3 classes\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","Net = Net.to(device)  # Set net to GPU or CPU\n","Net.load_state_dict(torch.load(model_path,  map_location=device)) # Load trained model\n","Net.eval() # Set to evaluation mode"],"metadata":{"id":"68ci_Fiwz0sB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668011131365,"user_tz":180,"elapsed":418,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}},"outputId":"f6162289-bd08-4989-f969-3326442c405b"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DeepLabV3(\n","  (backbone): IntermediateLayerGetter(\n","    (0): Conv2dNormActivation(\n","      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (2): Hardswish()\n","    )\n","    (1): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n","          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (2): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n","          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (3): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (4): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n","          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): ReLU()\n","          (scale_activation): Hardsigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (5): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): ReLU()\n","          (scale_activation): Hardsigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (6): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n","          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): ReLU()\n","          (scale_activation): Hardsigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (7): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n","          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (8): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n","          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (9): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (10): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n","          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): Conv2dNormActivation(\n","          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (11): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n","          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): ReLU()\n","          (scale_activation): Hardsigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (12): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): ReLU()\n","          (scale_activation): Hardsigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (13): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=672, bias=False)\n","          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): ReLU()\n","          (scale_activation): Hardsigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (14): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): ReLU()\n","          (scale_activation): Hardsigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (15): InvertedResidual(\n","      (block): Sequential(\n","        (0): Conv2dNormActivation(\n","          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (1): Conv2dNormActivation(\n","          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=960, bias=False)\n","          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","          (2): Hardswish()\n","        )\n","        (2): SqueezeExcitation(\n","          (avgpool): AdaptiveAvgPool2d(output_size=1)\n","          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n","          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n","          (activation): ReLU()\n","          (scale_activation): Hardsigmoid()\n","        )\n","        (3): Conv2dNormActivation(\n","          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (16): Conv2dNormActivation(\n","      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (2): Hardswish()\n","    )\n","  )\n","  (classifier): DeepLabHead(\n","    (0): ASPP(\n","      (convs): ModuleList(\n","        (0): Sequential(\n","          (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","        )\n","        (1): ASPPConv(\n","          (0): Conv2d(960, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","        )\n","        (2): ASPPConv(\n","          (0): Conv2d(960, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","        )\n","        (3): ASPPConv(\n","          (0): Conv2d(960, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","        )\n","        (4): ASPPPooling(\n","          (0): AdaptiveAvgPool2d(output_size=1)\n","          (1): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): ReLU()\n","        )\n","      )\n","      (project): Sequential(\n","        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","        (3): Dropout(p=0.5, inplace=False)\n","      )\n","    )\n","    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): ReLU()\n","    (4): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (aux_classifier): FCNHead(\n","    (0): Conv2d(40, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.1, inplace=False)\n","    (4): Conv2d(10, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["test_dataloader = DataLoader(CustomImageDataset(df[df['Status'] == 'Test']), batch_size=1, shuffle=False)"],"metadata":{"id":"hEH5xMxO6Cfy","executionInfo":{"status":"ok","timestamp":1668011131367,"user_tz":180,"elapsed":10,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["test_metrics = {'accuracy': [], 'precision_macro' : [], 'precision_micro' : [], 'recall' : [], \n","               'f1_macro' : [], 'f1_micro' : []}"],"metadata":{"id":"WuaaRDqPo7ml","executionInfo":{"status":"ok","timestamp":1668011131368,"user_tz":180,"elapsed":10,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["Net.eval()\n","with torch.no_grad():\n","  # Iterar sobre o dataloader da validação, configurar o batchsize por questões de memória\n","  for images, mask in test_dataloader:\n","    \n","    mask = mask.squeeze()\n","    AnnMap = np.zeros(mask.shape,np.float32)\n","    AnnMap[mask != 0] = 1 # set to 1 only the pixels that corresponds to the mask\n","  \n","    images = torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n","    mask = torch.autograd.Variable(mask, requires_grad=False).to(device) # Load annotation\n","    #print(mask.shape)\n","    Pred = Net(images)['out'] # make prediction\n","\n","    # ---- CALCULANDO MÉTRICAS ----- #\n","    seg = torch.argmax(Pred,1).cpu().detach().numpy()  # Get  prediction classes\n","  \n","    # Accuracy\n","    accuracy = accuracy_score(AnnMap.flatten(), seg.flatten())\n","    # Precision\n","    precision_macro = precision_score(AnnMap.flatten(), seg.flatten(), average='macro')\n","    precision_micro = precision_score(AnnMap.flatten(), seg.flatten(), average='micro')\n","    # Recall:    \n","    recall = recall_score(AnnMap.flatten(), seg.flatten())\n","    # F1\n","    f1_macro = f1_score(AnnMap.flatten(), seg.flatten(), average='macro')\n","    f1_micro = f1_score(AnnMap.flatten(), seg.flatten(), average='micro')    \n","    \n","    # #print(f'Accuracy: {accuracy}, Precision_macro: {precision_macro}, Precision_micro: {precision_micro}, F1_macro: {f1_macro}, F1_micro: {f1_micro}, Recall: {recall}')\n","\n","\n","    test_metrics['accuracy'].append(accuracy)\n","    test_metrics['recall'].append(recall)\n","    test_metrics['precision_macro'].append(precision_macro)\n","    test_metrics['precision_micro'].append(precision_micro)      \n","    test_metrics['f1_macro'].append(f1_macro)\n","    test_metrics['f1_micro'].append(f1_micro)"],"metadata":{"id":"H1GJzWpm6OL5","executionInfo":{"status":"ok","timestamp":1668011350824,"user_tz":180,"elapsed":219465,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["test_results = pd.DataFrame(test_metrics)"],"metadata":{"id":"tHx24f5opBnU","executionInfo":{"status":"ok","timestamp":1668011350827,"user_tz":180,"elapsed":46,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["test_results.mean(axis=0)"],"metadata":{"id":"XwNWSAw8pYQ5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668011350828,"user_tz":180,"elapsed":43,"user":{"displayName":"NEP Corte","userId":"14883523365544643318"}},"outputId":"c8e95b18-38b6-4a04-ab45-0b2165aa4e7a"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["accuracy           0.993759\n","precision_macro    0.978002\n","precision_micro    0.993759\n","recall             0.968126\n","f1_macro           0.979923\n","f1_micro           0.993759\n","dtype: float64"]},"metadata":{},"execution_count":21}]}],"metadata":{"colab":{"provenance":[{"file_id":"1C_miXtm4kCKYst3GjKD8q0SAzMRAjBfa","timestamp":1668008219272},{"file_id":"1GexIy3r705iVm_ErN3cQdveq3x0Sk6Fd","timestamp":1667994385740}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"b5bb342c42f5423bb066d55585b6b99d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d87e6eb180d4a0d921761f06243c8b0","IPY_MODEL_e211ce52b5b84f399e13f5859eec634f","IPY_MODEL_b4590a7e175d419f9cab3ce9f3d8bee7"],"layout":"IPY_MODEL_cf02a7ead714498a8de5a14d1d933f3a"}},"9d87e6eb180d4a0d921761f06243c8b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3451b7664e847ee9e559aefe028e673","placeholder":"​","style":"IPY_MODEL_bccb09acb21e45889a26d16b5e27bde5","value":"100%"}},"e211ce52b5b84f399e13f5859eec634f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb98741145a45a88463e3b3d6290c56","max":44356159,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc1324c637bb4426b98c30237e616050","value":44356159}},"b4590a7e175d419f9cab3ce9f3d8bee7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f74965bf97d54d498456f9471e9132d7","placeholder":"​","style":"IPY_MODEL_0923df46111e4878957d63730f87cfea","value":" 42.3M/42.3M [00:00&lt;00:00, 95.9MB/s]"}},"cf02a7ead714498a8de5a14d1d933f3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3451b7664e847ee9e559aefe028e673":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bccb09acb21e45889a26d16b5e27bde5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeb98741145a45a88463e3b3d6290c56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc1324c637bb4426b98c30237e616050":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f74965bf97d54d498456f9471e9132d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0923df46111e4878957d63730f87cfea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}